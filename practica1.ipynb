{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.977 · Análisis de sentimientos y textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencias de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PAC 1: Procesamiento y análisis de información textual\n",
    "\n",
    "En esta práctica revisaremos y aplicaremos los conocimientos aprendidos en el módulo 1. Concretamente trataremos 4 temas.\n",
    "\n",
    "1. **Obtención de datos a partir de información textual**: Búsqueda de términos unipalabra, colocaciones y vectorizaciones de términos.\n",
    "2. **Obtención de datos a partir de recursos externos al texto**: Similitud de significado con Wordnet y ConceptNet.\n",
    "3. **Interpretación de los datos**: Detectar temas.  \n",
    "4. **Predicción**: Clasificación de textos.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtención de datos a partir de información textual (5 puntos)\n",
    "\n",
    "Primero, cargamos las librerías necesarias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguiremos utilizando el dataset ArticlesMarch2018.csv visto en el módulo 1. Si lo abrís veréis que tiene 15 campos (columnas). Esta vez, además del campo headline, que ya se utilizó en el notebook del módulo 1, también utilizaremos el campo snippet y keywords.\n",
    "\n",
    "Recordemos el contenido de cada campo:\n",
    "\n",
    "<ul><b>Headline</b>: titulares</ul>\n",
    "<ul><b>Snippet</b>: contenido de las noticias encabezadas por los titulares</ul>\n",
    "<ul><b>Keywords</b>: palabras más relevantes de las noticias según sus redactores</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= KEYWORDS ========\n",
      "['bitcoin (currency)', 'electric light and power', 'united states economy', 'labor and jobs', 'productivity', 'united states defense and military forces', 'north korea', 'united states international relations', 'united states politics and government', 'embargoes and sanctions']\n"
     ]
    }
   ],
   "source": [
    "#Transformamos el dataset en un dataframe\n",
    "df= pd.read_csv(\"ArticlesMarch2018.csv\")\n",
    "\n",
    "#Concatenemos los valores de los campos headline y snippet para obtener un texto plano.\n",
    "headline_texts = \" \".join(df.headline.tolist()) #text plano\n",
    "snippet_texts = \" \".join(df.snippet.tolist()) #text plano\n",
    "\n",
    "#Preparamos las keywords\n",
    "\n",
    "keywords = []\n",
    "\n",
    "todelete = ['[', ']', '\\'']\n",
    "\n",
    "for l in df.keywords.tolist():\n",
    "    for td in todelete:\n",
    "        l = l.lower().replace(td, '')\n",
    "    keywords = keywords + l.split(', ')\n",
    "\n",
    "print(\"========= KEYWORDS ========\")\n",
    "print(keywords[:10])\n",
    "\n",
    "#Creamos un corpus a partir del cual haremos entrenamiento de modelos. Es la unión de los textos del campo \n",
    "#headlines y los textos del campo snippets\n",
    "\n",
    "sentences_for_modelling = df.headline.tolist() + df.headline.tolist() # lista\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Encontrar términos unipalabra (0.5 puntos)\n",
    "\n",
    "<b>Ejercicio 1</b>\n",
    "\n",
    "<ul>\n",
    "<li>Listar 100 términos unipalabra del campo <i>headline</i> que no sean stopwords.</li>\n",
    "<li>Lo mismo pero con el campo <i>snippet</i>. Los términos tienen que aparecer en minúscula.</li>\n",
    "</ul>\n",
    "    \n",
    "<b>En este ejercicio, consideramos términos unipalabra a los tokens que empiezan y acaban con un caracter alfabético (e.g: 'casa' (SÍ), @casa (NO), casa26 (NO))</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    <strong>Implementación:</strong><ul>Repasad en el módulo PLA1 la diferencia entre token y término.</ul>\n",
    "    <ul>Utilizad el tokenizador del paquete NLTK y filtrad los stopwords también con NLTK</ul>\n",
    "    <ul>Para saber si los términos unipalabra más frecuentes son suficientemente informativos, calculad su intersección con el campo <b>keywords</b></ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contestad las siguientes preguntas, razonando las respuestas:\n",
    "\n",
    "<ul><b>¿Cuál es el porcentaje de términos unipalabra que aparecen en el campo <i>snippet</i> y aparecen también en <i>headline?</i></b></ul>\n",
    "<ul><b>¿Crees que los primeros 100 términos unipalabra más frecuentes hallados en el campo <i>snippet</i> son suficientemente informativos para hacer un análisis detallado?</b></ul>\n",
    "<ul><b>¿Alguno de estos términos más frecuentes los añadirías a la lista de stopwords?</b></ul>\n",
    "<ul><b>Hay entradas sin titular marcadas con la palabra 'unknown', que no queremos considerar. ¿Pondrías esta palabra en la lista de stopwords?<ul><b></b></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN PREGUNTA 1                       #\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN PREGUNTA 2                       #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta a la pregunta 3\n",
    "\n",
    "Escribe aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta a la pregunta 4\n",
    "\n",
    "Escribe aquí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Encontrar colocaciones (2.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 2</b>\n",
    "\n",
    "Calcularemos las colocaciones más relevantes de los <b>snippets</b> según las métricas: <b>PMI</b> y <b>Likehood Ratio</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong>  A partir del texto de los snippets, computaremos los bigramas y trigramas más probables de ser una colocación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este apartado, habrá que cargar las librerías siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.collocations import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Primer paso:\n",
    "    \n",
    "A partir del comando help(nltk.collocations.BigramAssocMeasures) explora la clase BigramAssocMeasures del módulo nltk.metrics.association y revisa las definiciones de las medidas de Likelihood Ratio (likelihood_ratio) y de Pointwise Mutual Information (pmi) en las secciones que se indican en el capítulo 5 del libro Foundations of Statistical Natural Language Processing (Manning & Schutze).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BigramAssocMeasures in module nltk.metrics.association:\n",
      "\n",
      "class BigramAssocMeasures(NgramAssocMeasures)\n",
      " |  A collection of bigram association measures. Each association measure\n",
      " |  is provided as a function with three arguments::\n",
      " |  \n",
      " |      bigram_score_fn(n_ii, (n_ix, n_xi), n_xx)\n",
      " |  \n",
      " |  The arguments constitute the marginals of a contingency table, counting\n",
      " |  the occurrences of particular events in a corpus. The letter i in the\n",
      " |  suffix refers to the appearance of the word in question, while x indicates\n",
      " |  the appearance of any word. Thus, for example:\n",
      " |  \n",
      " |      n_ii counts (w1, w2), i.e. the bigram being scored\n",
      " |      n_ix counts (w1, *)\n",
      " |      n_xi counts (*, w2)\n",
      " |      n_xx counts (*, *), i.e. any bigram\n",
      " |  \n",
      " |  This may be shown with respect to a contingency table::\n",
      " |  \n",
      " |              w1    ~w1\n",
      " |           ------ ------\n",
      " |       w2 | n_ii | n_oi | = n_xi\n",
      " |           ------ ------\n",
      " |      ~w2 | n_io | n_oo |\n",
      " |           ------ ------\n",
      " |           = n_ix        TOTAL = n_xx\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BigramAssocMeasures\n",
      " |      NgramAssocMeasures\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  chi_sq(n_ii, n_ix_xi_tuple, n_xx) from abc.ABCMeta\n",
      " |      Scores bigrams using chi-square, i.e. phi-sq multiplied by the number\n",
      " |      of bigrams, as in Manning and Schutze 5.3.3.\n",
      " |  \n",
      " |  fisher(*marginals) from abc.ABCMeta\n",
      " |      Scores bigrams using Fisher's Exact Test (Pedersen 1996).  Less\n",
      " |      sensitive to small counts than PMI or Chi Sq, but also more expensive\n",
      " |      to compute. Requires scipy.\n",
      " |  \n",
      " |  phi_sq(*marginals) from abc.ABCMeta\n",
      " |      Scores bigrams using phi-square, the square of the Pearson correlation\n",
      " |      coefficient.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  dice(n_ii, n_ix_xi_tuple, n_xx)\n",
      " |      Scores bigrams using Dice's coefficient.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  jaccard(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using the Jaccard index.\n",
      " |  \n",
      " |  likelihood_ratio(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using likelihood ratios as in Manning and Schutze 5.3.4.\n",
      " |  \n",
      " |  pmi(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams by pointwise mutual information, as in Manning and\n",
      " |      Schutze 5.4.\n",
      " |  \n",
      " |  poisson_stirling(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using the Poisson-Stirling measure.\n",
      " |  \n",
      " |  student_t(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using Student's t test with independence hypothesis\n",
      " |      for unigrams, as in Manning and Schutze 5.3.1.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  mi_like(*marginals, **kwargs)\n",
      " |      Scores ngrams using a variant of mutual information. The keyword\n",
      " |      argument power sets an exponent (default 3) for the numerator. No\n",
      " |      logarithm of the result is calculated.\n",
      " |  \n",
      " |  raw_freq(*marginals)\n",
      " |      Scores ngrams by their frequency\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.collocations.BigramAssocMeasures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Segundo paso:\n",
    "    Calcular los términos unipalabra del campo <b>snippets</b> (Ya hecho en 1.1)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Tercer paso: Computa los mil mejores bigramas y trigramas a partir de los términos unipalabra. Tal com se ha visto en el módulo 1, utiliza la medida <b>PMI</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Cuarto paso: Computa los mil mejores bigramas y trigramas a partir de los términos unipalabra, pero con la <b>Likehood Ratio</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 3</b>\n",
    "\n",
    "Calcularemos las colocaciones más relevantes de los <b>snippets</b> pero con el módulo <b>Phrases</b> de Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Previamente cargaremos el módulo Phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Preprocesa el texto que utilizaremos para entrenar el modelo de detección de phrases. Al resultado le llamaremos <b><i>stream</i></b>. Recuerda que, como vimos en el apartado 3.3 del notebook del módulo, el stream tiene que ser una lista de listas. Cada lista contiene los términos de una frase: e.g. [['virtual', 'coins', 'real', 'resources'],  ['u.s', 'advances', 'military', 'plans', 'for', 'north', 'korea'],  ['mr', 'trump', 'and', 'the', 'very', 'bad', 'judge']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Recuerda que no queremos considerar la palabra <b>unknown</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Entrena el modelo para detectar phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Utiliza el modelo para detectar las phrases de los snippets. Presenta las phrases que contengan más de una palabra (el caracter delimitador de Phrases por defecto es '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 4</b>\n",
    "\n",
    "Evaluación de los métodos de extracción de colocaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong>  Comparar los resultados de cada método (PMI, Log Likehood y Phrase) con las <b>Keywords</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "Primer paso: Encontrar la intersección entre la suma de bigramas y trigramas calculados con el método PMI y la lista de keywords\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "Segundo paso: Encontrar la intersección entre la suma de bigramas y trigramas calculados con el método Log Likehood y la lista de keywords</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "Tercer paso: Encontrar la intersección entre la suma de bigramas y trigramas calculados con el método Phrase y la lista de keywords\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis:</strong> Contesta las siguientes preguntas, razonando las respuestas:\n",
    "<ul>¿Los resultados de Phrase se pueden evaluar comparándolos con los resultados del método PMI y Log Likehood?</ul>\n",
    "    <ul>¿Qué mètodo crees que es mejor para sacar las colocaciones de los snippets?</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta pregunta 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe la respuesta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe la respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 5</b>\n",
    "\n",
    "Mejora los métodos de extracción de colocaciones con <b>información lingüística</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Mejora la gramática propuesta en el mòdulo 1 para detectar n-gramas añadiendo otros patrones sintácticos, por ejemplo patrones que combinen adjetivos y nombres.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos la clasificación de etiquetas PoS.\n",
    "\n",
    "<b>Etiquetas PoS</b>\n",
    "\n",
    "<ul>\n",
    "<li>DT: Determinante</li>\n",
    "<li>JJ: Adjetivo</li>\n",
    "<li>NN: Nombre en singular</li>\n",
    "<li>NNS: Nombre en plural</li>\n",
    "<li>VBD: Verbo en pasado</li>\n",
    "<li>VBG: Verbo en gerundio</li>\n",
    "<li>MD: Verbo modal</li>\n",
    "<li>IN: Preposición</li>\n",
    "<li>PRP: Pronombre</li>\n",
    "<li>RB: Adverbio</li>\n",
    "<li>CC: Conjunción coordinada</li>\n",
    "<li>CD: Numeral</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n",
    "#Propuesta del alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Vectorizar términos (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 6</b>: Entrenar un modelo word2vec de los titulares con los snippets (text_for_modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "        Primer paso: preprocesa el texto que utilizaremos para entrenar el modelo, haciendo un <b>stream</b>, como has hecho en el ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Segundo paso: entrena un modelo Word2Vec a partir del texto preprocesado. Recordemos que el paquete <b>gensim</b> implementa un método para entrenar modelos Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 7</b>:\n",
    "<li>\n",
    "        <ul>a) Mostrar visualmente los vectores de los términos según el modelo Word2Vec mediante TSNE</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Cargamos los paquetes necesarios. Recuerda que tienes que obtener el vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>\n",
    "<ul>b) Obtén los 10 términos similares al término 'president', que no sean stopwords, según el modelo Word2Vec. Utiliza el método <b>most_similar</b> de la clase Word2Vec, que veréis en <a>https://radimrehurek.com/gensim/models/word2vec.html</a> y en <a>https://stackoverflow.com/questions/50275623/difference-between-most-similar-and-similar-by-vector-in-gensim-word2vec</a>. El parámetro de las n palabras más similares es topn (e.g: topn = 50)</ul>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 8</b>:\n",
    "<li>\n",
    " <ul>a) Cargamos un modelo w2vec pre-entrenado: </ul>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> \n",
    "Cargamos un modelo Word2Vec entrenado previamente con todo el Google News dataset, con aproximadamente cien mil millones de palabras. <b>Atención: ¡el modelo ocupa casi 2 GB! y la carga puede tardar unos minutos.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Obtén los términos similares al término 'president' según el modelo pre-entrenado, que no sean stopwords. Como en el ejercicio 7, utiliza el método <b>most_similar</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuvieras que hacer un análisis de los artículos del New York Times, ¿utilizarías el modelo de Google News o crearías un modelo Word2Vec de cero, con las noticias de este periódico? Razona la respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta a la pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe la respuesta aquí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 9</b>:\n",
    "<li>\n",
    "    <ul>A partir del modelo de Google News, demuestra el sentido de la palabra 'apple' comprobando las palabras con las cuales comparte contexto</ul>\n",
    "    <ul>¿Es posible vincular un apple con Steve Jobs?</ul>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Obtención de datos a partir de recursos externos al texto (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado obtendremos datos de similitud semántica con los recursos <b>Wordnet</b> y <b>ConceptNet</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 WordNet (0.5 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accederemos a Wordnet a través de la librería nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de wordnet wup_similarity utiliza la métrica de similitud definida por la Wu and Palmer score en que el score (valor) depende de la distancia entre términos dentro del grafo de jerarquías de la ontología, que es el grafo que relaciona términos con sus hiperónimos e hipónimos (ver apartado 3.3.3 del documento \"Cómo interpretar y analizar automáticamente la información textual\" del módulo 1).\n",
    "\n",
    "Además de la distancia entre dos nodos a través del grafo, la distancia también tiene en cuenta el nivel de jerarquía (más abstracto o menos abstracto), asignando más similitud entre nodos de niveles más bajos (menos abstracto) que entre nodos de niveles más altos (más abstracto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ejercicio 10</b>: Comprueba que efectivamente la similitud de Wu and Palmer tiene el comportamiento esperado comparando las distancias entre pares de sinónimos en diferentes niveles de jerarquía (e.g. person vs human y kid vs child) y entre un término con un hipónimo y un hiperónimo (e.g: chair y table vs furniture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong>  Recuerda que, como hemos visto en el módulo 1 en el apartado 4.1, para buscar dentro de wordnet puedes utilizar el método synset (e.g. wn.synset ('dog.n.01')) pasándole un string que contenga el nombre de la palabra que se busca, la categoría gramatical (sólo buscaremos nombres, i.e 'n') y el índice por si hay más de una entrada. Por lo tanto, en nuestro caso, siempre haremos la búsqueda wn.synset ('palabra.n.01') o wn.synsets ('palabra','n') para acceder a todas las entradas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ConceptNet (0.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejercicio 11:</strong> A partir de la relación IsA de ConceptNet (http://api.conceptnet.io/r/IsA) extrae hiperónimos de los términos que has utilizado en el ejercicio anterior y compara sus distancias con los extraidos por WordNet. Explora también casos de phrases como 'United States' que con WordNet no se pueden explorar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Para acceder a la api de ConceptNet cargamos la siguiente librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Anàlisis:</strong> ¿Cuáles son las principales diferencias entre WordNet y ConceptNet?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta a la pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe la respuesta aquí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpretación de los datos: detección de temas. (2 puntos)\n",
    "\n",
    "En este apartado exploraremos cómo detectar temas en los documentos. Primero veremos cómo el clustering de las keywords de las noticias perfilan los temas. Utilizaremos el método de K-means, vectorizando las keywords con un vectorizador tf.idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, recogemos, para cada noticia, una lista de sus keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bitcoin (Currency)',\n",
       "  'Electric Light and Power',\n",
       "  'United States Economy',\n",
       "  'Labor and Jobs',\n",
       "  'Productivity'],\n",
       " ['United States Defense and Military Forces',\n",
       "  'North Korea',\n",
       "  'United States International Relations',\n",
       "  'United States Politics and Government',\n",
       "  'Embargoes and Sanctions',\n",
       "  'Civilian Casualties',\n",
       "  'Defense Department',\n",
       "  'Joint Chiefs of Staff'],\n",
       " ['Trump',\n",
       "  'Donald J',\n",
       "  'Curiel',\n",
       "  'Gonzalo P',\n",
       "  'United States Politics and Government',\n",
       "  'Decisions and Verdicts',\n",
       "  'Courts and the Judiciary',\n",
       "  'Mexico',\n",
       "  'Border Barriers']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ArticlesMarch2018.csv\")\n",
    "keywords_lists = df.keywords.tolist() #lista de keywords por noticia\n",
    "\n",
    "keywords_lists = list(map(lambda x: list(map(lambda y: y.strip(' \\'[]\\''), x.split(','))), keywords_lists))\n",
    "\n",
    "keywords_lists[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos cada lista de keywords en una cadena de palabras; es decir, en un documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bitcoin (Currency) Electric Light and Power United States Economy Labor and Jobs Productivity', 'United States Defense and Military Forces North Korea United States International Relations United States Politics and Government Embargoes and Sanctions Civilian Casualties Defense Department Joint Chiefs of Staff', 'Trump Donald J Curiel Gonzalo P United States Politics and Government Decisions and Verdicts Courts and the Judiciary Mexico Border Barriers']\n"
     ]
    }
   ],
   "source": [
    "keywords_docs = [\" \".join(l) for l in keywords_lists ]\n",
    "\n",
    "print(keywords_docs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 K-means (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejercicio 12:</strong> Clusteriza las keywords en 4 clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "<strong>Implementación:</strong>Vectorizamos los documentos con un tf.idf vectorizer, que tiene 'word' como tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Implementación:</strong> Visualiza las keywords en 4 clusters. Ten en cuenta que, en el paso anterior, los vectores ya están en una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejercicio 13:</strong> ¿La gráfica es suficientemente clara como para ver los términos que definen los temas? ¿Crees que aumentando el número de clusters se vería mejor? ¿O sería más esclarecedor listar los términos de cada cluster? Razona las respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuestas a las preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe las respuestas aquí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LDA (1 punto)\n",
    "\n",
    "Recordemos que en el notebook del módulo 1 hemos visto la aplicación del método LDA para extraer temas de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Utilizando el método LDA, extrae temas a partir de los conjuntos de keywords de las noticias. Experimenta con el parámetro num_topics hasta encontrar un conjunto de temas que encuentres informativo, y asigna nombres a los temas encontrados. La construcción del modelo LDA puede tardar más de 10 minutos para algunos casos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos, por cada noticia, la lista de sus keywords (keywords lists). Ver introducción apartado 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el módulo necesario para utilizar el método LDA y recordamos la definición de la función que se utiliza en el notebook de módulo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "def lda(terms):\n",
    "    dictionary = corpora.Dictionary(terms)\n",
    "\n",
    "    texts = terms\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, \n",
    "                                               num_topics=10, \n",
    "                                               random_state=1,\n",
    "                                               id2word = dictionary, \n",
    "                                               passes=500)\n",
    "\n",
    "    return ldamodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejercicio 14:</strong> Partiendo de la función LDA anterior explora modelos de temas a partir de la lista de keywords de las noticias. Utiliza diferentes valores para el campo num_topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicciones (2 puntos)\n",
    "\n",
    "La empresa S&S hizo la clasificación de los titulares TOP y NOTOP con titulares del New York Times durante la época Trump. Aquí comprobaremos si el clasificador es útil para clasificar titulares publicados ya en la era Biden. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejercicio 15:</strong>Crea un modelo de clasificación de titulares a partir de los titulares del fichero 'NYT-Comment-Headlines.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los titulares y las etiquetas TOP y NOTOP para emparejarlos para hacer el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('NYT-Comment-Headlines.csv', sep='\\t')\n",
    "\n",
    "data_headlines = []\n",
    "data_labels = []\n",
    "\n",
    "headlines = df['Headline'].tolist()\n",
    "tags = df['Tag'].tolist()\n",
    "\n",
    "for i in range(len(headlines)): \n",
    "    data_headlines.append(headlines[i]) \n",
    "    data_labels.append(tags[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Implementación:</strong> Vuelve a entrenar un modelo de predicción para TOP o NO TOP a partir de la vectorización TfIdf de los titulares. Utiliza los términos detectados por el modelo de detección de phrases.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librerías necesarias para el entrenamiento y la utilización del modelo. Además, cargamos el modelo de detección de phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "model_phrases = Phrases.load('model_phrases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Paso 1: Construye los vectores TfIdf de los titulares, utilizando como términos las phrases detectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Paso 2: Entrena el modelo clasificador utilizando Logistic Regression com en el notebook del módulo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejercicio 16:</strong> Toma diez titulares actuales de la sección de política del New York Times. Comprueba si el clasificador funciona para estos titulares. ¿Hay temas, como el Covid-19, que influyen en los resultados del clasificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "Paso 1: Utiliza el modelo entrenado para predecir la categoría TOP o NO TOP de los titulares del New York Times que has escogido. Ver las palabras más informativas para cada clase (TOP y NO TOP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\"> Paso 2: Según el número de comentarios que tiene cada noticia razona si los resultados son los esperables y, si no es así, ¿qué aspectos crees que puede haber influido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta a la pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe la respuesta aqui\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
